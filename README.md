# 2023-Big-Data-Driven-Artificial-Intelligence
This is the source code and materials for *Big Data Driven Artificial Intelligence* course in BNU, 2023 Spring.<br>
<br>
This course comprehensively introduces the latest developments in *Big Data Driven Artificial Intelligence*, including but not limited to *neural networks*, *deep learning*, *reinforcement learning*, *causal inference*, *generative models*, *language models*, and *AI for scientific discovery*. 

## Outline

#### Lecture-01: Introduction to Big Data and Artificial Intelligence;<br>
+  Providing an overview of the history and different schools of Artificial Intelligence.
+  Covering the latest advancements in big data driven AI technologies. 
+  Illustrating real-world applications such as ChatGPT and protein folding prediction.
+  References<br>
&nbsp;- *Machine intelligence, Nature 521, 435 (28 May 2015)*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://www.nature.com/articles/521435a)&nbsp;&nbsp;|<br>
&nbsp;- *Prediction and its limits, SCIENCE, 3 Feb 2017, Vol 355, Issue 6324 pp. 468-469*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://www.science.org/doi/10.1126/science.355.6324.468)&nbsp;&nbsp;|<br>
&nbsp;- *AI TRANSFORMS SCIENCE, SCIENCE, VOLUME 357, ISSUE 6346, 7 JUL 2017*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://www.science.org/toc/science/357/6346)&nbsp;&nbsp;|<br>
&nbsp;-*《皇帝的新脑》, Roger Penrose*;<br>
&nbsp;-*《人工智能的未来》, Jeff Hawkins*;<br>
&nbsp;-*《为什么：关于因果关系的新科学》, 朱迪亚·珀尔 / 达纳·麦肯齐*;<br>
#### Lecture-02: Automatic Differentiation and PyTorch Programming;<br>
+  Introducing automatic differentiation technique and its application scenarios.
+  Introducing the PyTorch automatic differentiation programming platform.
+  Providing an example of using PyTorch.
+  References<br>
&nbsp;- *Automatic Differentiation in Machine Learning: a Survey*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/1502.05767) |&nbsp;&nbsp;[Code](https://paperswithcode.com/paper/automatic-differentiation-in-machine-learning)&nbsp;&nbsp;|<br>
&nbsp;- *Gumbel-softmax-based Optimization: A Simple General Framework for Optimization Problems on Graphs*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/2004.07300)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://github.com/bnusss/GSO)&nbsp;&nbsp;|<br>
&nbsp;- *Categorical Reparameterization with Gumbel-Softmax*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/1611.01144)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://paperswithcode.com/paper/categorical-reparameterization-with-gumbel)&nbsp;&nbsp;|<br>
#### Lecture-03: Fundamentals of Machine Learning;<br>
+  What is machine learning and what are its simple classifications? 
+  What are the basic steps of machine learning? 
+  Performance evaluation and common issues in machine learning. 
+  Introduction to simple feedforward neural networks and backpropagation algorithm.
+  References<br>
&nbsp;- *A high-bias, low-variance introduction to Machine Learning for physicists*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/1803.08823) |&nbsp;&nbsp;[Code1](https://github.com/drckf/mlreview_notebooks)&nbsp;&nbsp;|&nbsp;&nbsp;[Code2](https://github.com/alexandreday/fast_density_clustering)&nbsp;&nbsp;|<br>
#### Lecture-04: Common Neural Network Architectures;<br>
+  Basic and common neural network architectures and programming practices such as feedforward neural networks, convolutional neural networks, and recurrent neural networks. 
+  Classification problems and practices in image processing and natural language processing.
+  Fundamental methods of data processing.
#### Lecture-05: Theory of Representation Learning;<br>
+  Representation learning theory.
+  Representation learning and transfer learning.
+  Pre-training and transfer learning.
+  Examples of transfer learning in image tasks.
+  Introduction to word embedding techniques and their applications.
+  References<br>
&nbsp;- *Learning Word Representations by Jointly Modeling Syntagmatic and Paradigmatic Relations*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](http://ofey.me/papers/wordrep_acl2015.pdf) |&nbsp;&nbsp;[Code](https://github.com/FeiSun/WordRep)&nbsp;&nbsp;|<br>
&nbsp;- *Efficient Estimation of Word Representations in Vector Space*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/1301.3781)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://paperswithcode.com/paper/efficient-estimation-of-word-representations)&nbsp;&nbsp;|<br>
&nbsp;- *Distributed Representations of Words and Phrases and their Compositionality*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/pdf/1310.4546.pdf)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://paperswithcode.com/paper/distributed-representations-of-words-and-1)&nbsp;&nbsp;|<br>
&nbsp;- *The Geometry of Culture: Analyzing Meaning through Word Embeddings*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/1803.09288)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://paperswithcode.com/paper/the-geometry-of-culture-analyzing-meaning)&nbsp;&nbsp;|<br>
&nbsp;- *Semantics derived automatically from language corpora contain human-like biases*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/1803.09288)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://paperswithcode.com/paper/semantics-derived-automatically-from-language)&nbsp;&nbsp;|<br>
&nbsp;- *Word embeddings quantify 100 years of gender and ethnic stereotypes*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://www.pnas.org/doi/10.1073/pnas.1720347115)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://paperswithcode.com/paper/word-embeddings-quantify-100-years-of-gender)&nbsp;&nbsp;|<br>
&nbsp;- *Combining satellite imagery and machine learning to predict poverty*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://www.science.org/doi/10.1126/science.aaf7894)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://github.com/nealjean/predicting-poverty)&nbsp;&nbsp;|&nbsp;&nbsp;[Website](http://sustain.stanford.edu/predicting-poverty)&nbsp;&nbsp;|<br>
&nbsp;- *Fighting poverty with data*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://www.science.org/doi/10.1126/science.aah5217)&nbsp;&nbsp;|<br>
#### Lecture-06: From Deep Neural Networks to Neural ODE;<br>
+  Numerical algorithms for solving ordinary differential equations.
+  Residual networks.
+  Principles of Neural ODE.
+  Application examples.
+  Optimal control and adjoint algorithm.
+  References<br>
&nbsp;- *Theory and Applications of AlexNet Convolutional Neural Network*.&nbsp;&nbsp;|&nbsp;&nbsp;[Link](https://zhuanlan.zhihu.com/p/116197079) |<br>
&nbsp;- *Very Deep Convolutional Networks for Large-Scale Image Recognition*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/1409.1556)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://paperswithcode.com/paper/very-deep-convolutional-networks-for-large)&nbsp;&nbsp;|<br>
&nbsp;- *FractalNet: Ultra-Deep Neural Networks without Residuals*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/1605.07648)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://paperswithcode.com/paper/fractalnet-ultra-deep-neural-networks-without)&nbsp;&nbsp;|<br>
&nbsp;- *Deep Residual Learning for Image Recognition*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/1512.03385)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://paperswithcode.com/paper/deep-residual-learning-for-image-recognition)&nbsp;&nbsp;|<br>
&nbsp;- *Identity Mappings in Deep Residual Networks*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/1603.05027)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://github.com/KaimingHe/resnet-1k-layers)&nbsp;&nbsp;|<br>
&nbsp;- *Neural Ordinary Differential Equations*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/pdf/1806.07366.pdf)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://github.com/rtqichen/torchdiffeq)&nbsp;&nbsp;|<br>
&nbsp;- *An empirical study of neural ordinal differential equations*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://linjianma.github.io/pdf/282_project_report_ode.pdf
)&nbsp;&nbsp;|&nbsp;&nbsp;[Code1]( https://github.com/rtqichen/torchdiffeq
)&nbsp;&nbsp;|&nbsp;&nbsp;[Code2](https://github.com/igfox/multi-output-glucose-forecasting
)&nbsp;&nbsp;|&nbsp;&nbsp;[Poster](https://linjianma.github.io/pdf/282_ODE_poster.pdf)&nbsp;&nbsp;|<br>
&nbsp;- *Deep Multi-Output Forecasting: Learning to Accurately Predict Blood Glucose Trajectories*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/1806.05357)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://github.com/igfox/multi-output-glucose-forecasting)&nbsp;&nbsp;|<br>
#### Lecture-07: Overview of Generative Models;<br>
+  The difference between generative models and predictive models.
+  Classification of generative models.
+  Introduction to generative models, including GANs, VAEs, Normalizing Flow, and Diffusion Model.
+  References<br>
&nbsp;- *3D Image Generation with Diffusion Models*.&nbsp;&nbsp;|&nbsp;&nbsp;[Link1](https://3d-diffusion.github.io)&nbsp;&nbsp;|&nbsp;&nbsp;[Link2](https://dreamfusion3d.github.io)&nbsp;&nbsp;|<br>
&nbsp;- *Generative chemistry: drug discovery with deep learning generative models*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://link.springer.com/article/10.1007/s00894-021-04674-8)&nbsp;&nbsp;|<br>
&nbsp;- *Human-instructed Deep Hierarchical Generative Learning for Automated Urban Planning*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/pdf/2212.00904v1.pdf)&nbsp;&nbsp;|&nbsp;&nbsp;[Website](https://deepai.org/publication/human-instructed-deep-hierarchical-generative-learning-for-automated-urban-planning)&nbsp;&nbsp;|<br>
&nbsp;- *FractalNet: Ultra-Deep Neural Networks without Residuals*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/1605.07648)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://paperswithcode.com/paper/fractalnet-ultra-deep-neural-networks-without)&nbsp;&nbsp;|<br>
&nbsp;- *Generative Models in Deep Learning. In: Synthetic Data for Deep Learning*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://link.springer.com/book/10.1007/978-3-030-75178-4)&nbsp;&nbsp;|<br>
&nbsp;- *Generative Adversarial Nets*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/1406.2661)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://github.com/goodfeli/adversarial)&nbsp;&nbsp;|<br>
&nbsp;- *An overview of gradient descent optimization algorithms*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/pdf/1609.04747.pdf)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://paperswithcode.com/paper/an-overview-of-gradient-descent-optimization)&nbsp;&nbsp;|<br>
&nbsp;- *Conditional Generative Adversarial Nets*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/1411.1784)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://paperswithcode.com/paper/conditional-generative-adversarial-nets)&nbsp;&nbsp;|<br>
&nbsp;- *Generative Adversarial Text to Image Synthesis*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/1605.05396)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://github.com/reedscot/icml2016)&nbsp;&nbsp;|<br>
&nbsp;- *Image-to-Image Translation with Conditional Adversarial Networks*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/1611.07004)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://github.com/phillipi/pix2pix)&nbsp;&nbsp;|<br>
&nbsp;- *Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/1703.10593)&nbsp;&nbsp;|&nbsp;&nbsp;[Code1](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix)&nbsp;&nbsp;|&nbsp;&nbsp;[Code2](https://github.com/junyanz/CycleGAN)&nbsp;&nbsp;|<br>
#### Lecture-08: From Transformer to ChatGPT;<br>
+  Attention mechanism.
+  Self-attention mechanism and network structure learning.
+  Introduction to Transformer architecture.
+  Applications of Transformer.
+  Self-supervised learning mechanism based on language models.
+  Introduction to architectures such as BERT, GPT-3, and ChatGPT.
#### Lecture-09: Graph Neural Networks;<br>
+  Graph and Network.
+  Basic principles of Graph Neural Networks.
+  Basic applications of Graph Neural Networks.
+  Node classification.
+  Data-driven modeling of complex systems based on Graph Neural Networks.
#### Lecture-10: Data-Driven Modeling of Complex Systems;<br>
+  Introduction to complex systems.
+  Modeling methods for complex systems.
+  Data-driven modeling methods for complex systems.
+  Complete closed loop system including decision-making and feedback.
+  Learning causal relationships.
+  Reinforcement learning framework based on world models.
#### Lecture-11: Causal Machine Learning;<br>
+  Causation and Correlation.
+  Introduction to Causal Inference.
+  Introduction to Causal Discovery.
+  Causal Representation Learning.
#### Lecture-12: Reinforcement Learning;<br>
+  Basic framework of reinforcement learning.
+  Classification of reinforcement learning.
+  Q-learning algorithm.
+  Deep reinforcement learning.
+  Reinforcement learning algorithms based on the World Model.
+  Causality and reinforcement learning.
+  Reinforcement learning and control/decision-making.

## Sources

  + 《深度学习原理与PyTorch实战（第2版）》 http://product.dangdang.com/29396811.html ;<br>
  + 《深度学习(deep learning)》 http://product.dangdang.com/25111382.html ;<br>
  + 《The Elements of Statistical Learning: Data Mining, Inference, and Prediction, Second Edition》 http://product.dangdang.com/27440239.html ;<br>
  
