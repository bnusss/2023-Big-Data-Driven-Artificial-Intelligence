# 2023-Big-Data-Driven-Artificial-Intelligence
This is the source code and materials for *Big Data Driven Artificial Intelligence* course in BNU, 2023 Spring.<br>
<br>
This course comprehensively introduces the latest developments in *Big Data Driven Artificial Intelligence*, including but not limited to *neural networks*, *deep learning*, *reinforcement learning*, *causal inference*, *generative models*, *language models*, and *AI for scientific discovery*. 

## Outline

#### Lecture-01: Introduction to Big Data and Artificial Intelligence;<br>
+  Providing an overview of the history and different schools of Artificial Intelligence.
+  Covering the latest advancements in big data driven AI technologies. 
+  Illustrating real-world applications such as ChatGPT and protein folding prediction.
+  References<br>
&nbsp;- *Machine intelligence, Nature 521, 435 (28 May 2015)*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://www.nature.com/articles/521435a)&nbsp;&nbsp;|<br>
&nbsp;- *Prediction and its limits, SCIENCE, 3 Feb 2017, Vol 355, Issue 6324 pp. 468-469*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://www.science.org/doi/10.1126/science.355.6324.468)&nbsp;&nbsp;|<br>
&nbsp;- *AI TRANSFORMS SCIENCE, SCIENCE, VOLUME 357, ISSUE 6346, 7 JUL 2017*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://www.science.org/toc/science/357/6346)&nbsp;&nbsp;|<br>
&nbsp;-*《皇帝的新脑》, Roger Penrose*;<br>
&nbsp;-*《人工智能的未来》, Jeff Hawkins*;<br>
&nbsp;-*《为什么：关于因果关系的新科学》, 朱迪亚·珀尔 / 达纳·麦肯齐*;<br>
#### Lecture-02: Automatic Differentiation and PyTorch Programming;<br>
+  Introducing automatic differentiation technique and its application scenarios.
+  Introducing the PyTorch automatic differentiation programming platform.
+  Providing an example of using PyTorch.
+  References<br>
&nbsp;- *Automatic Differentiation in Machine Learning: a Survey*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/1502.05767) |&nbsp;&nbsp;[Code](https://paperswithcode.com/paper/automatic-differentiation-in-machine-learning)&nbsp;&nbsp;|<br>
&nbsp;- *Gumbel-softmax-based Optimization: A Simple General Framework for Optimization Problems on Graphs*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/2004.07300)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://github.com/bnusss/GSO)&nbsp;&nbsp;|<br>
&nbsp;- *Categorical Reparameterization with Gumbel-Softmax*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/1611.01144)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://paperswithcode.com/paper/categorical-reparameterization-with-gumbel)&nbsp;&nbsp;|<br>
#### Lecture-03: Fundamentals of Machine Learning;<br>
+  What is machine learning and what are its simple classifications? 
+  What are the basic steps of machine learning? 
+  Performance evaluation and common issues in machine learning. 
+  Introduction to simple feedforward neural networks and backpropagation algorithm.
+  References<br>
&nbsp;- *A high-bias, low-variance introduction to Machine Learning for physicists*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/1803.08823) |&nbsp;&nbsp;[Code1](https://github.com/drckf/mlreview_notebooks)&nbsp;&nbsp;|&nbsp;&nbsp;[Code2](https://github.com/alexandreday/fast_density_clustering)&nbsp;&nbsp;|<br>
#### Lecture-04: Common Neural Network Architectures;<br>
+  Basic and common neural network architectures and programming practices such as feedforward neural networks, convolutional neural networks, and recurrent neural networks. 
+  Classification problems and practices in image processing and natural language processing.
+  Fundamental methods of data processing.
#### Lecture-05: Theory of Representation Learning;<br>
+  Representation learning theory.
+  Representation learning and transfer learning.
+  Pre-training and transfer learning.
+  Examples of transfer learning in image tasks.
+  Introduction to word embedding techniques and their applications.
+  References<br>
&nbsp;- *Learning Word Representations by Jointly Modeling Syntagmatic and Paradigmatic Relations*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](http://ofey.me/papers/wordrep_acl2015.pdf) |&nbsp;&nbsp;[Code](https://github.com/FeiSun/WordRep)&nbsp;&nbsp;|<br>
&nbsp;- *Efficient Estimation of Word Representations in Vector Space*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/1301.3781)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://paperswithcode.com/paper/efficient-estimation-of-word-representations)&nbsp;&nbsp;|<br>
&nbsp;- *Distributed Representations of Words and Phrases and their Compositionality*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/pdf/1310.4546.pdf)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://paperswithcode.com/paper/distributed-representations-of-words-and-1)&nbsp;&nbsp;|<br>
&nbsp;- *The Geometry of Culture: Analyzing Meaning through Word Embeddings*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/1803.09288)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://paperswithcode.com/paper/the-geometry-of-culture-analyzing-meaning)&nbsp;&nbsp;|<br>
&nbsp;- *Semantics derived automatically from language corpora contain human-like biases*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/1803.09288)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://paperswithcode.com/paper/semantics-derived-automatically-from-language)&nbsp;&nbsp;|<br>
&nbsp;- *Word embeddings quantify 100 years of gender and ethnic stereotypes*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://www.pnas.org/doi/10.1073/pnas.1720347115)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://paperswithcode.com/paper/word-embeddings-quantify-100-years-of-gender)&nbsp;&nbsp;|<br>
&nbsp;- *Combining satellite imagery and machine learning to predict poverty*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://www.science.org/doi/10.1126/science.aaf7894)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://github.com/nealjean/predicting-poverty)&nbsp;&nbsp;|&nbsp;&nbsp;[Website](http://sustain.stanford.edu/predicting-poverty)&nbsp;&nbsp;|<br>
&nbsp;- *Fighting poverty with data*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://www.science.org/doi/10.1126/science.aah5217)&nbsp;&nbsp;|<br>
#### Lecture-06: From Deep Neural Networks to Neural ODE;<br>
+  Numerical algorithms for solving ordinary differential equations.
+  Residual networks.
+  Principles of Neural ODE.
+  Application examples.
+  Optimal control and adjoint algorithm.
+  References<br>
&nbsp;- *Theory and Applications of AlexNet Convolutional Neural Network*.&nbsp;&nbsp;|&nbsp;&nbsp;[Link](https://zhuanlan.zhihu.com/p/116197079) |<br>
&nbsp;- *Very Deep Convolutional Networks for Large-Scale Image Recognition*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/1409.1556)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://paperswithcode.com/paper/very-deep-convolutional-networks-for-large)&nbsp;&nbsp;|<br>
&nbsp;- *FractalNet: Ultra-Deep Neural Networks without Residuals*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/1605.07648)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://paperswithcode.com/paper/fractalnet-ultra-deep-neural-networks-without)&nbsp;&nbsp;|<br>
&nbsp;- *Deep Residual Learning for Image Recognition*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/1512.03385)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://paperswithcode.com/paper/deep-residual-learning-for-image-recognition)&nbsp;&nbsp;|<br>
&nbsp;- *Identity Mappings in Deep Residual Networks*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/1603.05027)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://github.com/KaimingHe/resnet-1k-layers)&nbsp;&nbsp;|<br>
&nbsp;- *Neural Ordinary Differential Equations*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/pdf/1806.07366.pdf)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://github.com/rtqichen/torchdiffeq)&nbsp;&nbsp;|<br>
&nbsp;- *An empirical study of neural ordinal differential equations*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://linjianma.github.io/pdf/282_project_report_ode.pdf
)&nbsp;&nbsp;|&nbsp;&nbsp;[Code1]( https://github.com/rtqichen/torchdiffeq
)&nbsp;&nbsp;|&nbsp;&nbsp;[Code2](https://github.com/igfox/multi-output-glucose-forecasting
)&nbsp;&nbsp;|&nbsp;&nbsp;[Poster](https://linjianma.github.io/pdf/282_ODE_poster.pdf)&nbsp;&nbsp;|<br>
&nbsp;- *Deep Multi-Output Forecasting: Learning to Accurately Predict Blood Glucose Trajectories*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/1806.05357)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://github.com/igfox/multi-output-glucose-forecasting)&nbsp;&nbsp;|<br>
#### Lecture-07: Overview of Generative Models;<br>
+  The difference between generative models and predictive models.
+  Classification of generative models.
+  Introduction to generative models, including GANs, VAEs, Normalizing Flow, and Diffusion Model.
+  References I<br>
&nbsp;- *3D Image Generation with Diffusion Models*.&nbsp;&nbsp;|&nbsp;&nbsp;[Link1](https://3d-diffusion.github.io)&nbsp;&nbsp;|&nbsp;&nbsp;[Link2](https://dreamfusion3d.github.io)&nbsp;&nbsp;|<br>
&nbsp;- *Generative chemistry: drug discovery with deep learning generative models*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://link.springer.com/article/10.1007/s00894-021-04674-8)&nbsp;&nbsp;|<br>
&nbsp;- *Human-instructed Deep Hierarchical Generative Learning for Automated Urban Planning*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/pdf/2212.00904v1.pdf)&nbsp;&nbsp;|&nbsp;&nbsp;[Website](https://deepai.org/publication/human-instructed-deep-hierarchical-generative-learning-for-automated-urban-planning)&nbsp;&nbsp;|<br>
&nbsp;- *FractalNet: Ultra-Deep Neural Networks without Residuals*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/1605.07648)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://paperswithcode.com/paper/fractalnet-ultra-deep-neural-networks-without)&nbsp;&nbsp;|<br>
&nbsp;- *Generative Models in Deep Learning. In: Synthetic Data for Deep Learning*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://link.springer.com/book/10.1007/978-3-030-75178-4)&nbsp;&nbsp;|<br>
&nbsp;- *Generative Adversarial Nets*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/1406.2661)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://github.com/goodfeli/adversarial)&nbsp;&nbsp;|<br>
&nbsp;- *An overview of gradient descent optimization algorithms*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/pdf/1609.04747.pdf)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://paperswithcode.com/paper/an-overview-of-gradient-descent-optimization)&nbsp;&nbsp;|<br>
&nbsp;- *Conditional Generative Adversarial Nets*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/1411.1784)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://paperswithcode.com/paper/conditional-generative-adversarial-nets)&nbsp;&nbsp;|<br>
&nbsp;- *Generative Adversarial Text to Image Synthesis*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/1605.05396)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://github.com/reedscot/icml2016)&nbsp;&nbsp;|<br>
&nbsp;- *Image-to-Image Translation with Conditional Adversarial Networks*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/1611.07004)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://github.com/phillipi/pix2pix)&nbsp;&nbsp;|<br>
&nbsp;- *Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/1703.10593)&nbsp;&nbsp;|&nbsp;&nbsp;[Code1](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix)&nbsp;&nbsp;|&nbsp;&nbsp;[Code2](https://github.com/junyanz/CycleGAN)&nbsp;&nbsp;|<br>
+  References II<br>
&nbsp;- *What are Diffusion Models?*.&nbsp;&nbsp;|&nbsp;&nbsp;[Link](https://lilianweng.github.io/posts/2021-07-11-diffusion-models/)&nbsp;&nbsp;|<br>
&nbsp;- *From Autoencoder to Beta-VAE*.&nbsp;&nbsp;|&nbsp;&nbsp;[Link](https://lilianweng.github.io/posts/2018-08-12-vae/)&nbsp;&nbsp;|<br>
&nbsp;- *UC Berkeley -- Spring 2020 -- Deep Unsupervised Learning -- Pieter Abbeel, Peter Chen, Jonathan Ho, Aravind Srinivas, Alex Li, Wilson Yan -- L3 Flows*.&nbsp;&nbsp;|&nbsp;&nbsp;[Link](https://www.bilibili.com/video/BV1i741187Dp?p=3)&nbsp;&nbsp;|<br>
&nbsp;- *Density estimation using Real NVP*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/1605.08803)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://paperswithcode.com/paper/density-estimation-using-real-nvp)&nbsp;&nbsp;|<br>
&nbsp;- *Deep Unsupervised Learning using Nonequilibrium Thermodynamics*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/1503.03585)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://github.com/Sohl-Dickstein/Diffusion-Probabilistic-Models)&nbsp;&nbsp;|<br>
&nbsp;- *Generative Modeling by Estimating Gradients of the Data Distribution*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/1907.05600)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://github.com/ermongroup/ncsn)&nbsp;&nbsp;|&nbsp;&nbsp;[Link](https://yang-song.net/blog/2021/score/)&nbsp;&nbsp;|<br>
&nbsp;- *Denoising Diffusion Probabilistic Models*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/2006.11239)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://github.com/hojonathanho/diffusion)&nbsp;&nbsp;|<br>
&nbsp;- *U-Net: Convolutional Networks for Biomedical Image Segmentation*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://www.cs.helsinki.fi/u/ahyvarin/papers/JMLR05.pdf)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://paperswithcode.com/paper/u-net-convolutional-networks-for-biomedical)&nbsp;&nbsp;|<br>
&nbsp;- *Learning Transferable Visual Models From Natural Language Supervision*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/2103.00020)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://github.com/openai/CLIP)&nbsp;&nbsp;|<br>
&nbsp;- *Hierarchical Text-Conditional Image Generation with CLIP Latents*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/2204.06125)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://paperswithcode.com/paper/hierarchical-text-conditional-image)&nbsp;&nbsp;|<br>
&nbsp;- *A Survey on Generative Diffusion Model*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/2209.02646)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://github.com/chq1155/A-Survey-on-Generative-Diffusion-Model)&nbsp;&nbsp;|<br>
&nbsp;- *Diffusion Models: A Comprehensive Survey of Methods and Applications*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/2209.00796)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://github.com/YangLing0818/Diffusion-Models-Papers-Survey-Taxonomy)&nbsp;&nbsp;|<br>
#### Lecture-08: From Transformer to ChatGPT;<br>
+  Attention mechanism.
+  Self-attention mechanism and network structure learning.
+  Introduction to Transformer architecture.
+  Applications of Transformer.
+  Self-supervised learning mechanism based on language models.
+  Introduction to architectures such as BERT, GPT-3, and ChatGPT.
+  References<br>
&nbsp;- *Sparks of Artificial General Intelligence: Early experiments with GPT-4*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/2303.12712)&nbsp;&nbsp;|<br>
&nbsp;- *Learning Word Representations by Jointly Modeling Syntagmatic and Paradigmatic Relations*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://aclanthology.org/P15-1014.pdf)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://github.com/FeiSun/WordRep)&nbsp;&nbsp;|<br>
&nbsp;- *Convolutional Sequence to Sequence Learning*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/1705.03122)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://github.com/facebookresearch/fairseq)&nbsp;&nbsp;|<br>
&nbsp;- *Attention Is All You Need*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/1706.03762)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://github.com/tensorflow/tensor2tensor)&nbsp;&nbsp;|<br>
&nbsp;- *Neural Phrase-based Machine Translation*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/1706.05565v2)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://github.com/posenhuang/NPMT)&nbsp;&nbsp;|<br>
&nbsp;- *从word2vec开始，说下GPT庞大的家族系谱*.&nbsp;&nbsp;|&nbsp;&nbsp;[Link](https://cloud.tencent.com/developer/article/1731421)&nbsp;&nbsp;|<br>
&nbsp;- *BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/1810.04805)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://github.com/google-research/bert)&nbsp;&nbsp;|<br>
&nbsp;- *Improving Language Understanding by Generative Pre-Training*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://paperswithcode.com/paper/improving-language-understanding-by#code)&nbsp;&nbsp;|<br>
&nbsp;- *Super-NaturalInstructions: Generalization via Declarative Instructions on 1600+ NLP Tasks*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/2204.07705)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://github.com/allenai/natural-instructions)&nbsp;&nbsp;|<br>
&nbsp;- *人工反馈的强化学习*.&nbsp;&nbsp;|&nbsp;&nbsp;[Link](https://zhuanlan.zhihu.com/p/596059221)&nbsp;&nbsp;|<br>
&nbsp;- *Scaling Laws for Neural Language Models*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/2001.08361)&nbsp;&nbsp;|<br>
&nbsp;- *137 emergent abilities of large language models*.&nbsp;&nbsp;|&nbsp;&nbsp;[Link](https://www.jasonwei.net/blog/emergence)&nbsp;&nbsp;|<br>
&nbsp;- *A Survey on In-context Learning*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/2301.00234)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://github.com/dqxiu/icl_paperlist)&nbsp;&nbsp;|<br>
&nbsp;- *Why Can GPT Learn In-Context? Language Models Secretly Perform Gradient Descent as Meta-Optimizers*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/2212.10559)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://github.com/microsoft/lmops)&nbsp;&nbsp;|<br>
&nbsp;- *Prompt Engineering: 循循善诱*.&nbsp;&nbsp;|&nbsp;&nbsp;[Link](https://zhuanlan.zhihu.com/p/526299013)&nbsp;&nbsp;|<br>
&nbsp;- *通向 ChatGPT 及 AGI 的未解之谜*.&nbsp;&nbsp;|&nbsp;&nbsp;[Link](https://pattern.swarma.org/study_group_issue/409)&nbsp;&nbsp;|<br>
&nbsp;- *ChatGPT平替工具介绍*.&nbsp;&nbsp;|&nbsp;&nbsp;[Link](https://pattern.swarma.org/study_group_issue/451)&nbsp;&nbsp;|<br>

#### Lecture-09: Graph Neural Networks;<br>
+  Graph and Network.
+  Basic principles of Graph Neural Networks.
+  Basic applications of Graph Neural Networks.
+  Node classification.
+  Data-driven modeling of complex systems based on Graph Neural Networks.
+  References I<br>
&nbsp;- *A Comprehensive Survey on Graph Neural Networks*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/1901.00596)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://paperswithcode.com/paper/a-comprehensive-survey-on-graph-neural)&nbsp;&nbsp;|<br>
&nbsp;- *Geometric Deep Learning: Grids, Groups, Graphs, Geodesics, and Gauges*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/2104.13478)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://paperswithcode.com/paper/geometric-deep-learning-grids-groups-graphs)&nbsp;&nbsp;|<br>
&nbsp;- *DeepWalk: Online Learning of Social Representations*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/1403.6652)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://paperswithcode.com/paper/deepwalk-online-learning-of-social)&nbsp;&nbsp;|<br>
&nbsp;- *node2vec: Scalable Feature Learning for Networks*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/1607.00653)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://github.com/aditya-grover/node2vec)&nbsp;&nbsp;|<br>
&nbsp;- *Complex Network Classification with Convolutional Neural Network*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/1802.00539v2)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://github.com/bnusss/cnc_2017)&nbsp;&nbsp;|<br>
&nbsp;- *struc2vec: Learning Node Representations from Structural Identity*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/1704.03165)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://github.com/leoribeiro/struc2vec)&nbsp;&nbsp;|<br>
&nbsp;- *From Node Embedding To Community Embedding : A Hyperbolic Approach*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/1907.01662)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://paperswithcode.com/paper/learning-graph-structured-data-using-poincare)&nbsp;&nbsp;|<br>
&nbsp;- *Knowledge graph embedding by translating on hyperplanes*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://dl.acm.org/doi/10.5555/2893873.2894046)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://paperswithcode.com/paper/knowledge-graph-embedding-by-translating-on)&nbsp;&nbsp;|<br>
&nbsp;- *Deep Sets*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/1703.06114)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://paperswithcode.com/paper/deep-sets)&nbsp;&nbsp;|<br>
&nbsp;- *GRAPH CONVOLUTIONAL NETWORKS*.&nbsp;&nbsp;|&nbsp;&nbsp;[Link](https://tkipf.github.io/graph-convolutional-networks/)&nbsp;&nbsp;|<br>
&nbsp;- *Graph Attention Networks*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/1710.10903)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://github.com/PetarV-/GAT)&nbsp;&nbsp;|<br>
&nbsp;- *The Emerging Field of Signal Processing on Graphs: Extending High-Dimensional Data Analysis to Networks and Other Irregular Domains*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/1211.0053#:~:text=The%20emerging%20field%20of%20signal%20processing%20on%20graphs,harmonic%20analysis%20to%20process%20such%20signals%20on%20graphs.)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://github.com/epfl-lts2/pygsp)&nbsp;&nbsp;|<br>
&nbsp;- *Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/1606.09375)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://github.com/mdeff/cnn_graph)&nbsp;&nbsp;|<br>
+  References II<br>
&nbsp;- *Variational Graph Auto-Encoders*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/1611.07308)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://github.com/tkipf/gae)&nbsp;&nbsp;|<br>
&nbsp;- *VGAE（Variational graph auto-encoders）论文详解*.&nbsp;&nbsp;|&nbsp;&nbsp;[Link](https://zhuanlan.zhihu.com/p/78340397)&nbsp;&nbsp;|<br>
&nbsp;- *Learning Universal Network Representation via Link Prediction by Graph Convolutional Neural Network*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://ieeexplore.ieee.org/document/9355034)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://github.com/bnusss/DeepLinker)&nbsp;&nbsp;|<br>
&nbsp;- *Discovering latent node Information by graph attention network*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://www.nature.com/articles/s41598-021-85826-x)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://github.com/bnusss/DeepLinker)&nbsp;&nbsp;|<br>
&nbsp;- *Graph Attention Networks*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/1710.10903)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://github.com/PetarV-/GAT)&nbsp;&nbsp;|<br>
&nbsp;- *Network Completion: Beyond Matrix Completion*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://ieeexplore.ieee.org/document/9334012)&nbsp;&nbsp;|<br>
&nbsp;- *Kronecker graphs: An Approach to Modeling Network*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/0812.4905)&nbsp;&nbsp;|<br>
&nbsp;- *The Network Completion Problem: Inferring Missing Nodes and Edges in Networks*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/1710.10903)&nbsp;&nbsp;|<br>
&nbsp;- *Completing Networks by Learning Local Connection Patterns*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/2204.11852)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://github.com/3riccc/C-GIN)&nbsp;&nbsp;|<br>
&nbsp;- *How Powerful are Graph Neural Networks?*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/1810.00826)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://github.com/weihua916/powerful-gnns)&nbsp;&nbsp;|<br>
&nbsp;- *Generative Graph Convolutional Network for Growing Graphs*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/1903.02640)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://paperswithcode.com/paper/generative-graph-convolutional-network-for)&nbsp;&nbsp;|<br>
&nbsp;- *DeepNC: Deep Generative Network Completion*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://ieeexplore.ieee.org/document/9229516)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://github.com/congasix/DeepNC)&nbsp;&nbsp;|<br>
&nbsp;- *A Systematic Survey on Deep Generative Models for Graph Generation*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://ieeexplore.ieee.org/document/9920219)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://paperswithcode.com/paper/a-systematic-survey-on-deep-generative-models)&nbsp;&nbsp;|<br>
&nbsp;- *GraphRNN: Generating Realistic Graphs with Deep Auto-regressive Models*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/1802.08773)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://github.com/snap-stanford/GraphRNN)&nbsp;&nbsp;|<br>
&nbsp;- *A Survey on Deep Graph Generation: Methods and Applications*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/2203.06714)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://paperswithcode.com/paper/a-survey-on-deep-graph-generation-methods-and)&nbsp;&nbsp;|<br>
&nbsp;- *Graph Normalizing Flows*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/1905.13177)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://github.com/jliu/graph-normalizing-flows)&nbsp;&nbsp;|<br>
&nbsp;- *UC Berkeley -- Spring 2020 -- Deep Unsupervised Learning -- Pieter Abbeel, Peter Chen, Jonathan Ho, Aravind Srinivas, Alex Li, Wilson Yan -- L3 Flows*.&nbsp;&nbsp;|&nbsp;&nbsp;[Link](https://sites.google.com/view/berkeley-cs294-158-sp20/home)&nbsp;&nbsp;|<br>
&nbsp;- *Density estimation using Real NVP*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/1605.08803)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://paperswithcode.com/paper/density-estimation-using-real-nvp)&nbsp;&nbsp;|<br>
&nbsp;- *Generative Diffusion Models on Graphs: Methods and Applications*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/2302.02591)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://paperswithcode.com/paper/generative-diffusion-models-on-graphs-methods)&nbsp;&nbsp;|<br>

#### Lecture-10: Data-Driven Modeling of Complex Systems;<br>
+  Introduction to complex systems.
+  Modeling methods for complex systems.
+  Data-driven modeling methods for complex systems.
+  Complete closed loop system including decision-making and feedback.
+  Learning causal relationships.
+  Reinforcement learning framework based on world models.
+  References<br>
&nbsp;- *Investigating time, strength, and duration of measures in controlling the spread of COVID-19 using a networked meta-population model*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://link.springer.com/article/10.1007/s11071-020-05769-2)&nbsp;&nbsp;|<br>
&nbsp;- *Takens's theorem*.&nbsp;&nbsp;|&nbsp;&nbsp;[Link](https://en.wikipedia.org/wiki/Takens's_theorem)&nbsp;&nbsp;|<br>
&nbsp;- *Deep Multi-Output Forecasting: Learning to Accurately Predict Blood Glucose Trajectories*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://www.kdd.org/kdd2018/accepted-papers/view/deep-multi-output-forecasting-learning-to-accurately-predict-blood-glucose-)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://github.com/igfox/multi-output-glucose-forecasting)&nbsp;&nbsp;|<br>
&nbsp;- *Reservoir computing*.&nbsp;&nbsp;|&nbsp;&nbsp;[Link](https://en.wikipedia.org/wiki/Reservoir_computing)&nbsp;&nbsp;|<br>
&nbsp;- *Model-Free Prediction of Large Spatiotemporally Chaotic Systems from Data: A Reservoir Computing Approach..&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/1905.13177)&nbsp;&nbsp;|<br>
&nbsp;- *PM2.5-GNN: A Domain Knowledge Enhanced Graph Neural Network For PM2.5 Forecasting*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://dl.acm.org/doi/abs/10.1145/3397536.3422208)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://github.com/bnusss/PM2.5-GNN)&nbsp;&nbsp;|<br>
&nbsp;- *Universal framework for reconstructing complex networks and node dynamics from discrete or continuous dynamics data*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://journals.aps.org/pre/abstract/10.1103/PhysRevE.106.034315)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://github.com/bnusss/AIDD)&nbsp;&nbsp;|<br>
&nbsp;- *A General Deep Learning Framework for Network Reconstruction and Dynamics Learning*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/1812.11482v3)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://github.com/bnusss/GGN)&nbsp;&nbsp;|<br>
&nbsp;- *Categorical Reparameterization with Gumbel-Softmax*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/1611.01144)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://paperswithcode.com/paper/categorical-reparameterization-with-gumbel)&nbsp;&nbsp;|<br>
&nbsp;- *Model-free inference of direct network interactions from nonlinear collective dynamics*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://www.nature.com/articles/s41467-017-02288-4)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://github.com/networkinference/ARNI)&nbsp;&nbsp;|<br>
&nbsp;- *Neural Relational Inference for Interacting Systems*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/1802.04687)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://github.com/ethanfetaya/nri)&nbsp;&nbsp;|<br>
&nbsp;- *Discovering latent node Information by graph attention network.*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://www.nature.com/articles/s41598-021-85826-x)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://github.com/bnusss/DeepLinker)&nbsp;&nbsp;|<br>
&nbsp;- *HighAir: A Hierarchical Graph Neural Network-Based Air Quality Forecasting Method.*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/2101.04264v1)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://github.com/Friger/HighAir)&nbsp;&nbsp;|<br>
&nbsp;- *Multi-Scale Spatial Temporal Graph Convolutional Network for Skeleton-Based Action Recognition.*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/2206.13028)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://github.com/czhaneva/mst-gcn)&nbsp;&nbsp;|<br>
&nbsp;- *Graph U-Nets.*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/1905.05178)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://github.com/HongyangGao/Graph-U-Nets)&nbsp;&nbsp;|<br>
&nbsp;- *U-Net: Convolutional Networks for Biomedical Image Segmentation.*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/1505.04597)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://paperswithcode.com/paper/u-net-convolutional-networks-for-biomedical)&nbsp;&nbsp;|<br>
&nbsp;- *Deep Learning for Prediction of the Air Quality Response to Emission Changes.*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://pubs.acs.org/doi/10.1021/acs.est.0c02923)&nbsp;&nbsp;|<br>
&nbsp;- *Estimates and 25-year trends of the global burden of disease attributable to ambient air pollution: an analysis of data from the Global Burden of Diseases Study 2015.*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://www.sciencedirect.com/science/article/pii/S0140673617305056)&nbsp;&nbsp;|<br>
&nbsp;- *Learning to Simulate Complex Physics with Graph Networks.*.&nbsp;&nbsp;|&nbsp;&nbsp;[Paper](https://arxiv.org/abs/2002.09405)&nbsp;&nbsp;|&nbsp;&nbsp;[Code](https://github.com/deepmind/deepmind-research/tree/master/learning_to_simulate)&nbsp;&nbsp;|<br>

#### Lecture-11: Causal Machine Learning;<br>
+  Causation and Correlation.
+  Introduction to Causal Inference.
+  Introduction to Causal Discovery.
+  Causal Representation Learning.
#### Lecture-12: Reinforcement Learning;<br>
+  Basic framework of reinforcement learning.
+  Classification of reinforcement learning.
+  Q-learning algorithm.
+  Deep reinforcement learning.
+  Reinforcement learning algorithms based on the World Model.
+  Causality and reinforcement learning.
+  Reinforcement learning and control/decision-making.

## Sources

  + 《深度学习原理与PyTorch实战（第2版）》 http://product.dangdang.com/29396811.html ;<br>
  + 《深度学习(deep learning)》 http://product.dangdang.com/25111382.html ;<br>
  + 《The Elements of Statistical Learning: Data Mining, Inference, and Prediction, Second Edition》 http://product.dangdang.com/27440239.html ;<br>
  
